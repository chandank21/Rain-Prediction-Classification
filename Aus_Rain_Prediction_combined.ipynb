{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "\n",
    "# Loadind DATA from KAGGLE\n",
    "\n",
    "print(\"Downloadind DATA..\")\n",
    "#data_url = 'https://www.kaggle.com/jsphyg/weather-dataset-rattle-package'\n",
    "#od.download(data_url)\n",
    "data_dir = './weather-dataset-rattle-package/weatherAUS.csv'\n",
    "rain_df = pd.read_csv(data_dir)\n",
    "rain_df.dropna(subset=['RainToday','RainTomorrow'],inplace=True)\n",
    "\n",
    "# Spliting DATA in Train,Validation and Test set based on Year\n",
    "\n",
    "Year = pd.to_datetime(rain_df.Date).dt.year\n",
    "rain_df['RainTomprrow']   = rain_df.RainTomorrow.map({'No':0,'Yes':1})\n",
    "train_df, val_df, test_df = rain_df[Year<2015], rain_df[Year == 2015], rain_df[Year>2015]\n",
    "\n",
    "# Spliting Input and target DATA set\n",
    "input_cols, target_col = rain_df.columns[1:-1], rain_df.columns[-1]\n",
    "train_input, train_target = train_df[input_cols].copy(), train_df[target_col].copy()\n",
    "val_input, val_target     = val_df[input_cols].copy(), val_df[target_col].copy()\n",
    "test_input, test_target   = test_df[input_cols].copy(),test_df[target_col].copy()\n",
    "\n",
    "# Splitting columns in Numerical and Categorical\n",
    "\n",
    "numeric_cols = train_input.select_dtypes(include=np.number).columns.tolist()[:-1]\n",
    "categorical_cols = train_input.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# IMPUTING(Filling Missing Values ) of numericals columns\n",
    "\n",
    "print(\"IMPUTING(Filling Missing Values with their MEAN) of numericals columns\")\n",
    "imputer=SimpleImputer(strategy='mean')\n",
    "imputer.fit(rain_df[numeric_cols])\n",
    "train_input[numeric_cols] = imputer.transform(train_input[numeric_cols])\n",
    "val_input[numeric_cols] = imputer.transform(val_input[numeric_cols])\n",
    "test_input[numeric_cols] = imputer.transform(test_input[numeric_cols])\n",
    "\n",
    "# Scaling Numerical DATA\n",
    "\n",
    "print(\"Scaling Numerical DATA Using MinMaxScaler...\")\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(rain_df[numeric_cols])\n",
    "train_input[numeric_cols] = scaler.transform(train_input[numeric_cols])\n",
    "val_input[numeric_cols] = scaler.transform(val_input[numeric_cols])\n",
    "test_input[numeric_cols] = scaler.transform(test_input[numeric_cols])\n",
    "\n",
    "# Encoding Categorical DATA\n",
    "\n",
    "print(\"Encoding Categorical DATA....\")\n",
    "encoder = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "encoder.fit(rain_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names(categorical_cols))\n",
    "train_input[encoded_cols] = encoder.transform(train_input[categorical_cols])\n",
    "val_input[encoded_cols] = encoder.transform(val_input[categorical_cols])\n",
    "test_input[encoded_cols] = encoder.transform(test_input[categorical_cols])\n",
    "print(\"Data is Ready to Put In Model\")\n",
    "\n",
    "#Creatind data for fitting,prediction and accuracy measure\n",
    "x_train = train_input[numeric_cols + encoded_cols]\n",
    "x_val = val_input[numeric_cols + encoded_cols]\n",
    "x_test = test_input[numeric_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating & Training  Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import seaborn as sns\n",
    "\n",
    "# Creating Linear Regression Models\n",
    "\n",
    "print(\"Creating LogisticRegression Model...\")\n",
    "LR_model=LogisticRegression(solver='liblinear',max_iter=100)\n",
    "LR_model.fit(x_train,train_target)\n",
    "# Displaying weights of each features\n",
    "weight_df=pd.DataFrame({'feature':numeric_cols+encoded_cols,\n",
    "             'weights':LR_model.coef_.tolist()[0]})\n",
    "sns.barplot(data=weight_df.sort_values('weights',ascending=False).head(20),x='weights',y='feature')\n",
    "print(\"Model is created\")\n",
    "\n",
    "# Creating Dicision Tree Classifier Models\n",
    "\n",
    "DT_base_model=DecisionTreeClassifier(random_state=42).fit(x_train,train_target)\n",
    "DT_accurate_model=DecisionTreeClassifier(max_depth=9,\n",
    "                                         max_leaf_nodes=150,\n",
    "                                         random_state=42).fit(x_train,train_target)\n",
    "\n",
    "#Creating Random Forest Classifier Models\n",
    "\n",
    "RF_base_model=DecisionTreeClassifier(random_state=42).fit(x_train,train_target)\n",
    "RF_accurate_model=DecisionTreeClassifier(n_estimators=100,\n",
    "                                         max_depth=40,\n",
    "                                         max_leaf_nodes=150,\n",
    "                                         max_features=7,\n",
    "                                         n_jobs=-1,\n",
    "                                         random_state=42).fit(x_train,train_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def predict_plot(inputs,target,name=''):\n",
    "    predicted=model.predict(inputs)\n",
    "    accuracy=accuracy_score(target,predicted)\n",
    "    print(\"Accuracy of model on \",name,\" set=\",accuracy*100,\"%\")\n",
    "    matri=confusion_matrix(target,predicted,normalize='true')\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.heatmap(matri,annot=True)\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('Target')\n",
    "    plt.title('{} Confusion Matrix'.format(name))\n",
    "\n",
    "# Accuracy Score and Confusion matrix on Each Data set\n",
    "\n",
    "predict_plot(x_train,train_target,'Training')\n",
    "predict_plot(x_val,val_target,'Validation')\n",
    "predict_plot(x_test,test_target,'TEST')\n",
    "\n",
    "# Evaluting accuarcy on Random and Aways_No Dataset \n",
    "random_target=np.random.choice([1,0],len(x_test))\n",
    "print(\"Accuracy for Random_Yes&No_data\",accuracy_score(test_target,random_target))\n",
    "always_no_target=np.zeros(len(x_test))\n",
    "print(\"Accuracy for Always_No_data\",accuracy_score(test_target,always_no_target)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model to predict one input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Is_Rain_Tomorrow(rain_data):\n",
    "    x_data=pd.DataFrame([rain_data])\n",
    "    x_data[numeric_cols]=imputer.transform(x_data[numeric_cols])\n",
    "    x_data[numeric_cols]=scaler.transform(x_data[numeric_cols])\n",
    "    x_data[encoded_cols]=encoder.transform(x_data[categorical_cols])\n",
    "    predicted=model.predict(x_data[numeric_cols+encoded_cols])[0]\n",
    "    predicted_prob=model.predict_proba(x_data[numeric_cols+encoded_cols])\n",
    "    return predicted,predicted_prob[0][list(model.classes_).index(predicted)]\n",
    "\n",
    "new_input = {'Date': '2021-06-19','Location': 'Katherine','MinTemp': 23.2,'MaxTemp': 33.2,'Rainfall': 10.2,\n",
    "             'Evaporation': 4.2,'Sunshine': np.nan,'WindGustDir': 'NNW','WindGustSpeed': 52.0,'WindDir9am': 'NW',\n",
    "             'WindDir3pm': 'NNE','WindSpeed9am': 13.0,'WindSpeed3pm': 20.0,'Humidity9am': 89.0,'Humidity3pm': 58.0,\n",
    "             'Pressure9am': 1004.8,'Pressure3pm': 1001.5,'Cloud9am': 8.0,'Cloud3pm': 5.0,'Temp9am': 25.7,\n",
    "             'Temp3pm': 33.0,'RainToday': 'Yes'}\n",
    "if Is_Rain_Tomorrow(new_input)[0]:\n",
    "    print(\"Possiblity of RainTomorrow is: \",Is_Rain_Tomorrow(new_input)[1])\n",
    "else:\n",
    "    print(\"Possibility of Not_Rain_Tomorrow is: \",Is_Rain_Tomorrow(new_input)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "australia_rain = {\n",
    "    'model': model,\n",
    "    'imputer': imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'input_cols': input_cols,\n",
    "    'target_col': target_col,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'encoded_cols': encoded_cols\n",
    "}\n",
    "joblib.dump(australia_rain, 'australia_rain.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
